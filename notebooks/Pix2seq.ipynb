{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CO1A6ZlGtN-"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/quickdraw_dataset/sketchrnn/cat.npz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4GvzWJkDDNT"
      },
      "outputs": [],
      "source": [
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lH9-QGb_xT9i"
      },
      "outputs": [],
      "source": [
        "!pip install cairosvg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALJJldo3iYKX"
      },
      "outputs": [],
      "source": [
        "!pip install svgwrite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbzcD-m49_dP"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import Optional, Tuple, Any\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import einops\n",
        "\n",
        "from PIL import Image\n",
        "import cairosvg\n",
        "import os\n",
        "from six.moves import range\n",
        "import svgwrite\n",
        "import io\n",
        "import torch.nn.functional as F\n",
        "from datetime import datetime\n",
        "from typing import Optional, Tuple, Any, List\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm6NASJyjUoa"
      },
      "outputs": [],
      "source": [
        "def get_bounds(data, factor=10):\n",
        "    \"\"\"Return bounds of data.\"\"\"\n",
        "    min_x = 0\n",
        "    max_x = 0\n",
        "    min_y = 0\n",
        "    max_y = 0\n",
        "\n",
        "    abs_x = 0\n",
        "    abs_y = 0\n",
        "    for i in range(len(data)):\n",
        "        x = float(data[i, 0]) / factor\n",
        "        y = float(data[i, 1]) / factor\n",
        "        abs_x += x\n",
        "        abs_y += y\n",
        "        min_x = min(min_x, abs_x)\n",
        "        min_y = min(min_y, abs_y)\n",
        "        max_x = max(max_x, abs_x)\n",
        "        max_y = max(max_y, abs_y)\n",
        "\n",
        "    return min_x, max_x, min_y, max_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHOwTBiEiSjJ"
      },
      "outputs": [],
      "source": [
        "def draw_strokes(data, svg_filename, factor=0.2, padding=50):\n",
        "    \"\"\"\n",
        "    little function that displays vector images and saves them to .svg\n",
        "    :param data:\n",
        "    :param factor:\n",
        "    :param svg_filename:\n",
        "    :param padding:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    min_x, max_x, min_y, max_y = get_bounds(data, factor)\n",
        "    dims = (padding + max_x - min_x, padding + max_y - min_y)\n",
        "    dwg = svgwrite.Drawing(size=dims)\n",
        "    dwg.add(dwg.rect(insert=(0, 0), size=dims, fill='white'))\n",
        "    lift_pen = 1\n",
        "    abs_x = int(padding / 2) - min_x\n",
        "    abs_y = int(padding / 2) - min_y\n",
        "    p = \"M%s, %s \" % (abs_x, abs_y)\n",
        "    # use lowcase for relative position\n",
        "    command = \"m\"\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        if lift_pen == 1:\n",
        "            command = \"m\"\n",
        "        elif command != \"l\":\n",
        "            command = \"l\"\n",
        "        else:\n",
        "            command = \"\"\n",
        "        x = float(data[i, 0]) / factor\n",
        "        y = float(data[i, 1]) / factor\n",
        "        lift_pen = data[i, 2]\n",
        "        p += command + str(x) + \", \" + str(y) + \" \"\n",
        "    the_color = \"black\"\n",
        "    stroke_width = 1\n",
        "\n",
        "    dwg.add(dwg.path(p).stroke(the_color, stroke_width).fill(\"none\"))\n",
        "    #dwg.save()\n",
        "\n",
        "    svg_code = dwg.tostring()\n",
        "    img = cairosvg.svg2png(bytestring=svg_code)\n",
        "    image = Image.open(io.BytesIO(img))\n",
        "    image = image.resize((48,48))\n",
        "    #image = image.convert('1')\n",
        "    aarr = np.asarray(image)\n",
        "    aarr = np.where(aarr < 255, 0, 255)\n",
        "    aarr = aarr[:,:,1]\n",
        "    # aarr = np.reshape(aarr, (28*28))\n",
        "    # np.save('array', aarr)\n",
        "    #image.save(svg_filename + '.png')\n",
        "    return dims, dwg.tostring(), aarr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vg7nT39JamgW"
      },
      "outputs": [],
      "source": [
        "def load_dataset(data_dir, data_set, percentage):\n",
        "    \"\"\"Loads the .npz file, and splits the set into train/valid/test.\"\"\"\n",
        "\n",
        "    img_H, img_W = 48, 48\n",
        "\n",
        "    if isinstance(data_set, list):\n",
        "        datasets = data_set\n",
        "    else:\n",
        "        datasets = [data_set]\n",
        "\n",
        "    train_strokes = None\n",
        "    valid_strokes = None\n",
        "    test_strokes = None\n",
        "    \n",
        "    nb_strokes = {}\n",
        "    png_paths_map = {'train': [], 'valid': [], 'test': []}\n",
        "\n",
        "    for dataset in datasets:\n",
        "        \n",
        "        data_filepath = os.path.join(data_dir, 'data', dataset)\n",
        "        data = np.load(data_filepath, encoding='latin1', allow_pickle=True)\n",
        "        print('Loaded {}/{}/{} from {}'.format(\n",
        "            len(data['train'][:int(len(data['train']) * percentage)]),\n",
        "            len(data['valid'][:int(len(data['valid']) * percentage)] ),\n",
        "            len(data['test'][:int(len(data['test']) * percentage)] ),\n",
        "            dataset))\n",
        "        \n",
        "        nb_strokes[dataset] = { 'train':int(len(data['train']) * percentage),\n",
        "                                'valid':int(len(data['valid']) * percentage),\n",
        "                                'test':int(len(data['test']) * percentage) }\n",
        "\n",
        "        \n",
        "        if train_strokes is None:\n",
        "            train_strokes = data['train'][:int(len(data['train']) * percentage)]  # [N (#sketches),], each with [S (#points), 3]\n",
        "            valid_strokes = data['valid'][:int(len(data['valid']) * percentage)] \n",
        "            test_strokes = data['test'][:int(len(data['test']) * percentage)] \n",
        "        else:\n",
        "            train_strokes = np.concatenate((train_strokes, data['train'][:int(len(data['train']) * percentage)] ))\n",
        "            valid_strokes = np.concatenate((valid_strokes, data['valid'][:int(len(data['valid']) * percentage)] ))\n",
        "            test_strokes = np.concatenate((test_strokes, data['test'][:int(len(data['test']) * percentage)] ))\n",
        "\n",
        "        splits = ['train', 'valid', 'test']\n",
        "        for split in splits:\n",
        "            for im_idx in range(len(data[split][:int(len(data[split]) * percentage)] ) ):\n",
        "                png_path = os.path.join(data_dir, 'png', dataset[:-4], split,\n",
        "                                        str(img_H) + 'x' + str(img_W), str(im_idx) + '.png')\n",
        "                png_paths_map[split].append(png_path)\n",
        "\n",
        "    all_strokes = np.concatenate((train_strokes, valid_strokes, test_strokes))\n",
        "    num_points = 0\n",
        "    for stroke in all_strokes:\n",
        "        num_points += len(stroke)\n",
        "    avg_len = num_points / len(all_strokes)\n",
        "    print('Dataset combined: {} ({}/{}/{}), avg len {}'.format(\n",
        "        len(all_strokes), len(train_strokes), len(valid_strokes),\n",
        "        len(test_strokes), int(avg_len)))\n",
        "    assert len(train_strokes) == len(png_paths_map['train'])\n",
        "    assert len(valid_strokes) == len(png_paths_map['valid'])\n",
        "    assert len(test_strokes) == len(png_paths_map['test'])\n",
        "\n",
        "    result = {'train':train_strokes, 'valid': valid_strokes, 'test': test_strokes}\n",
        "    png_paths = {'train':png_paths_map['train'], 'valid':png_paths_map['valid'], 'test':png_paths_map['test']}\n",
        "    return result, png_paths, nb_strokes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Nm2TnJ5w9nD"
      },
      "outputs": [],
      "source": [
        "def pad_image(png_filename, pngsize):\n",
        "    curr_png = Image.open(png_filename).convert('RGB')\n",
        "    png_curr_w = curr_png.width\n",
        "    png_curr_h = curr_png.height\n",
        "    print(\"pngsize: {}, {}\".format(pngsize[0],pngsize[1]))\n",
        "\n",
        "    if png_curr_w != pngsize[0] and png_curr_h != pngsize[1]:\n",
        "        print('Not aligned', 'png_curr_w', png_curr_w, 'png_curr_h', png_curr_h)\n",
        "\n",
        "    padded_png = np.zeros(shape=[pngsize[1], pngsize[0], 3], dtype=np.uint8)\n",
        "    padded_png.fill(255)\n",
        "\n",
        "    if png_curr_w > png_curr_h:\n",
        "        pad = int(round((png_curr_w - png_curr_h) / 2))\n",
        "        padded_png[pad: pad + png_curr_h, :png_curr_w, :] = np.array(curr_png, dtype=np.uint8)\n",
        "    else:\n",
        "        pad = int(round((png_curr_h - png_curr_w) / 2))\n",
        "        padded_png[:png_curr_h, pad: pad + png_curr_w, :] = np.array(curr_png, dtype=np.uint8)\n",
        "\n",
        "    padded_png = Image.fromarray(padded_png, 'RGB')\n",
        "    padded_png.save(png_filename, 'PNG')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABNDnquuxL4Z"
      },
      "outputs": [],
      "source": [
        "def svg2png(dwg_string, svgsize, pngsize, png_filename, padding=False):\n",
        "    \"\"\"convert svg into png, using cairosvg\"\"\"\n",
        "    svg_w, svg_h = svgsize\n",
        "    png_w, png_h = pngsize\n",
        "    x_scale = png_w / svg_w\n",
        "    y_scale = png_h / svg_h\n",
        "\n",
        "    if x_scale > y_scale:\n",
        "        cairosvg.svg2png(bytestring=dwg_string, write_to=png_filename, output_height=png_h)\n",
        "    else:\n",
        "        cairosvg.svg2png(bytestring=dwg_string, write_to=png_filename, output_width=png_w)\n",
        "\n",
        "    if padding:\n",
        "        pad_image(png_filename, pngsize)\n",
        "    img = Image.open(png_filename)\n",
        "    img = img.resize((48,48))\n",
        "    img = np.asarray(img)\n",
        "    img = np.where(img < 254, 0, 255).astype(np.uint8)\n",
        "    #plt.imshow(img)\n",
        "    img = Image.fromarray(img)\n",
        "    img.save(png_filename, 'PNG')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bqaodMly5oz"
      },
      "outputs": [],
      "source": [
        "def render_svg2bitmap(data_base_dir, data_set, percentage):\n",
        "    \"\"\"get sketch as png\"\"\"\n",
        "    img_H, img_W = 250, 250\n",
        "\n",
        "    npz_dir = os.path.join(data_base_dir, 'npz')\n",
        "    svg_dir = os.path.join(data_base_dir, 'svg')\n",
        "    png_dir = os.path.join(data_base_dir, 'png')\n",
        "\n",
        "    datasets, png_paths, nb_strokes = load_dataset(data_base_dir, data_set, percentage)\n",
        "    \n",
        "    nb_img = {'train':0, 'valid':0, 'test':0}\n",
        "    \n",
        "    for dataset_i in data_set:\n",
        "        assert dataset_i[-4:] == '.npz'\n",
        "        cate_svg_dir = os.path.join(svg_dir, dataset_i[:-4])\n",
        "        cate_png_dir = os.path.join(png_dir, dataset_i[:-4])\n",
        "\n",
        "        data_types = ['train', 'valid', 'test']\n",
        "        for data_type in data_types:\n",
        "            split_cate_svg_dir = os.path.join(cate_svg_dir, data_type)\n",
        "            split_cate_png_dir = os.path.join(cate_png_dir, data_type,\n",
        "                                              str(48) + 'x' + str(48))\n",
        "\n",
        "            os.makedirs(split_cate_svg_dir, exist_ok=True)\n",
        "            os.makedirs(split_cate_png_dir, exist_ok=True)\n",
        "\n",
        "            split_dataset = datasets[data_type]\n",
        "            split_png_path = png_paths[data_type]\n",
        "            nb_strokes_dataset = nb_strokes[dataset_i][data_type]             \n",
        "\n",
        "            for _ in range(nb_strokes_dataset):                \n",
        "                stroke = np.copy(split_dataset[nb_img[data_type]])                \n",
        "                png_path = split_png_path[nb_img[data_type]]\n",
        "                print(png_path, 'stroke.shape', stroke.shape)\n",
        "                actual_idx = png_path[len(split_cate_png_dir) + 1:-4]\n",
        "                svg_path = os.path.join(split_cate_svg_dir, str(actual_idx) + '.svg')\n",
        "                \n",
        "        \n",
        "                svg_size, dwg_bytestring, _ = draw_strokes(stroke, svg_path, padding=10)  # (w, h)\n",
        "                svg2png(dwg_bytestring, svg_size, (img_W, img_H), png_path,\n",
        "                               padding=True)\n",
        "                nb_img[data_type] += 1\n",
        "                \n",
        "#render_svg2bitmap('./', ['duck.npz', 'elephant.npz', 'giraffe.npz'], 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqIY89YgkNRS"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "import matplotlib.pyplot as plt\n",
        "datasets, png_paths, _ = load_dataset('./', ['cat.npz'], 0.01)\n",
        "stroke = np.copy(datasets['train'][0])\n",
        "svg_size, dwg_bytestring, aarr = draw_strokes(stroke, './', padding=10)\n",
        "#cairosvg.svg2png(bytestring=dwg_bytestring, write_to='./cat.png')\n",
        "\n",
        "#svg2png(dwg_bytestring, svg_size, (250, 250), './cat.png',padding=True)\n",
        "#print(png_paths['train'][0])\n",
        "#print(aarr.shape)\n",
        "#plt.imshow(aarr)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSgcOTcP-Oag"
      },
      "outputs": [],
      "source": [
        "class StrokesDataset(Dataset):\n",
        "    \"\"\"\n",
        "    ## Dataset\n",
        "    This class loads and pre-processes the data.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset: np.array, max_seq_length: int, png_paths:list, scale: Optional[float] = None):\n",
        "        \"\"\"\n",
        "        `dataset` is a list of numpy arrays of shape [seq_len, 3].\n",
        "        It is a sequence of strokes, and each stroke is represented by\n",
        "        3 integers.\n",
        "        First two are the displacements along x and y ($\\Delta x$, $\\Delta y$)\n",
        "        and the last integer represents the state of the pen, $1$ if it's touching\n",
        "        the paper and $0$ otherwise.\n",
        "        \"\"\"\n",
        "        data = []\n",
        "        # We iterate through each of the sequences and filter\n",
        "        for seq in dataset:\n",
        "            # Filter if the length of the sequence of strokes is within our range\n",
        "            if 10 < len(seq) <= max_seq_length:\n",
        "                # Clamp $\\Delta x$, $\\Delta y$ to $[-1000, 1000]$\n",
        "                seq = np.minimum(seq, 1000)\n",
        "                seq = np.maximum(seq, -1000)\n",
        "                # Convert to a floating point array and add to `data`\n",
        "                seq = np.array(seq, dtype=np.float32)\n",
        "                data.append(seq)\n",
        "\n",
        "        # We then calculate the scaling factor which is the\n",
        "        # standard deviation of ($\\Delta x$, $\\Delta y$) combined.\n",
        "        # Paper notes that the mean is not adjusted for simplicity,\n",
        "        # since the mean is anyway close to $0$.\n",
        "        if scale is None:\n",
        "            scale = np.std(np.concatenate([np.ravel(s[:, 0:2]) for s in data]))\n",
        "        self.scale = scale\n",
        "\n",
        "        # Get the longest sequence length among all sequences\n",
        "        longest_seq_len = max([len(seq) for seq in data])\n",
        "\n",
        "        # We initialize PyTorch data array with two extra steps for start-of-sequence (sos)\n",
        "        # and end-of-sequence (eos).\n",
        "        # Each step is a vector $(\\Delta x, \\Delta y, p_1, p_2, p_3)$.\n",
        "        # Only one of $p_1, p_2, p_3$ is $1$ and the others are $0$.\n",
        "        # They represent *pen down*, *pen up* and *end-of-sequence* in that order.\n",
        "        # $p_1$ is $1$ if the pen touches the paper in the next step.\n",
        "        # $p_2$ is $1$ if the pen doesn't touch the paper in the next step.\n",
        "        # $p_3$ is $1$ if it is the end of the drawing.\n",
        "        self.data = torch.zeros(len(data), longest_seq_len + 2, 5, dtype=torch.float)\n",
        "        # The mask array needs only one extra-step since it is for the outputs of the\n",
        "        # decoder, which takes in `data[:-1]` and predicts next step.\n",
        "        self.mask = torch.zeros(len(data), longest_seq_len + 1)\n",
        "\n",
        "        for i, seq in enumerate(data):\n",
        "            seq = torch.from_numpy(seq)\n",
        "            len_seq = len(seq)\n",
        "            # Scale and set $\\Delta x, \\Delta y$\n",
        "            self.data[i, 1:len_seq + 1, :2] = seq[:, :2] / scale\n",
        "            # $p_1$\n",
        "            self.data[i, 1:len_seq + 1, 2] = 1 - seq[:, 2]\n",
        "            # $p_2$\n",
        "            self.data[i, 1:len_seq + 1, 3] = seq[:, 2]\n",
        "            # $p_3$\n",
        "            self.data[i, len_seq + 1:, 4] = 1\n",
        "            # Mask is on until end of sequence\n",
        "            self.mask[i, :len_seq + 1] = 1\n",
        "\n",
        "        # Start-of-sequence is $(0, 0, 1, 0, 0)$\n",
        "        self.data[:, 0, 2] = 1\n",
        "\n",
        "        self.png_paths = png_paths\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Size of the dataset\"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        \"\"\"Get a sample\"\"\"\n",
        "        img = Image.open(self.png_paths[idx]).convert('L')\n",
        "        img = np.array(img)\n",
        "        return self.data[idx], self.mask[idx], img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "data_sets = ['cat.npz', 'duck.npz']\n",
        "datasets, png_paths, _ = load_dataset('./', data_sets, 0.01)\n",
        "max_seq_length = 150\n",
        "# Create training dataset\n",
        "train_dataset = StrokesDataset(datasets['train'], max_seq_length, png_paths['train'])\n",
        "_,_, img = train_dataset[0]\n",
        "print(img.shape)\n",
        "plt.imshow(img)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ibb7Lsym-V96"
      },
      "outputs": [],
      "source": [
        "class BivariateGaussianMixture:\n",
        "    \"\"\"\n",
        "    ## Bi-variate Gaussian mixture\n",
        "    The mixture is represented by $\\Pi$ and\n",
        "    $\\mathcal{N}(\\mu_{x}, \\mu_{y}, \\sigma_{x}, \\sigma_{y}, \\rho_{xy})$.\n",
        "    This class adjusts temperatures and creates the categorical and Gaussian\n",
        "    distributions from the parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, pi_logits: torch.Tensor, mu_x: torch.Tensor, mu_y: torch.Tensor,\n",
        "                 sigma_x: torch.Tensor, sigma_y: torch.Tensor, rho_xy: torch.Tensor):\n",
        "        self.pi_logits = pi_logits\n",
        "        self.mu_x = mu_x\n",
        "        self.mu_y = mu_y\n",
        "        self.sigma_x = sigma_x\n",
        "        self.sigma_y = sigma_y\n",
        "        self.rho_xy = rho_xy\n",
        "\n",
        "    @property\n",
        "    def n_distributions(self):\n",
        "        \"\"\"Number of distributions in the mixture, $M$\"\"\"\n",
        "        return self.pi_logits.shape[-1]\n",
        "\n",
        "    def set_temperature(self, temperature: float):\n",
        "        \"\"\"\n",
        "        Adjust by temperature $\\tau$\n",
        "        \"\"\"\n",
        "        # $$\\hat{\\Pi_k} \\leftarrow \\frac{\\hat{\\Pi_k}}{\\tau}$$\n",
        "        self.pi_logits /= temperature\n",
        "        # $$\\sigma^2_x \\leftarrow \\sigma^2_x \\tau$$\n",
        "        self.sigma_x *= math.sqrt(temperature)\n",
        "        # $$\\sigma^2_y \\leftarrow \\sigma^2_y \\tau$$\n",
        "        self.sigma_y *= math.sqrt(temperature)\n",
        "\n",
        "    def get_distribution(self):\n",
        "        # Clamp $\\sigma_x$, $\\sigma_y$ and $\\rho_{xy}$ to avoid getting `NaN`s\n",
        "        sigma_x = torch.clamp_min(self.sigma_x, 1e-5)\n",
        "        sigma_y = torch.clamp_min(self.sigma_y, 1e-5)\n",
        "        rho_xy = torch.clamp(self.rho_xy, -1 + 1e-5, 1 - 1e-5)\n",
        "\n",
        "        # Get means\n",
        "        mean = torch.stack([self.mu_x, self.mu_y], -1)\n",
        "        # Get covariance matrix\n",
        "        cov = torch.stack([\n",
        "            sigma_x * sigma_x, rho_xy * sigma_x * sigma_y,\n",
        "            rho_xy * sigma_x * sigma_y, sigma_y * sigma_y\n",
        "        ], -1)\n",
        "        cov = cov.view(*sigma_y.shape, 2, 2)\n",
        "\n",
        "        # Create bi-variate normal distribution.\n",
        "        #\n",
        "        # 📝 It would be efficient to `scale_tril` matrix as `[[a, 0], [b, c]]`\n",
        "        # where\n",
        "        # $$a = \\sigma_x, b = \\rho_{xy} \\sigma_y, c = \\sigma_y \\sqrt{1 - \\rho^2_{xy}}$$.\n",
        "        # But for simplicity we use co-variance matrix.\n",
        "        # [This is a good resource](https://www2.stat.duke.edu/courses/Spring12/sta104.1/Lectures/Lec22.pdf)\n",
        "        # if you want to read up more about bi-variate distributions, their co-variance matrix,\n",
        "        # and probability density function.\n",
        "        multi_dist = torch.distributions.MultivariateNormal(mean, covariance_matrix=cov)\n",
        "\n",
        "        # Create categorical distribution $\\Pi$ from logits\n",
        "        cat_dist = torch.distributions.Categorical(logits=self.pi_logits)\n",
        "\n",
        "        #\n",
        "        return cat_dist, multi_dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7OuONF5-cWT"
      },
      "outputs": [],
      "source": [
        "class EncoderCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    ## Encoder module\n",
        "    This consists of a bidirectional LSTM\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_z: int):\n",
        "        super().__init__()\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "        self.filter_hp = torch.tensor([[[[-1, -1, -1],\n",
        "                                             [-1, 8, -1],\n",
        "                                             [-1, -1, -1]]]]).float().to(self.device)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels= 4, kernel_size = 2, stride =2)\n",
        "        self.conv2 = nn.Conv2d(in_channels = 4, out_channels= 4, kernel_size = 2, stride =1)\n",
        "        self.conv3 = nn.Conv2d(in_channels = 4, out_channels= 8, kernel_size = 2, stride =2)\n",
        "        self.conv4 = nn.Conv2d(in_channels = 8, out_channels= 8, kernel_size = 2, stride =1)\n",
        "        self.conv5 = nn.Conv2d(in_channels = 8, out_channels= 8, kernel_size = 2, stride =2)\n",
        "        self.conv6 = nn.Conv2d(in_channels = 8, out_channels= 8, kernel_size = 2, stride =1)\n",
        "\n",
        "        # Head to get $\\mu$\n",
        "        self.mu_head = nn.Linear(128, d_z)\n",
        "        # Head to get $\\hat{\\sigma}$\n",
        "        self.sigma_head = nn.Linear(128, d_z)\n",
        "\n",
        "    def high_pass_filtering(self, img_in):\n",
        "        \"\"\"\n",
        "        high pass filtering\n",
        "        :param img_in: [N, H, W, 1]\n",
        "        :return: img_out: [N, H, W, 1]\n",
        "        \"\"\"\n",
        "        img_out = F.conv2d(img_in, self.filter_hp)\n",
        "        return img_out\n",
        "\n",
        "\n",
        "    def forward(self, inputs: torch.Tensor, state=None):\n",
        "        x = self.high_pass_filtering(inputs)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = torch.tanh(self.conv6(x))\n",
        "        \n",
        "        x = x.view(inputs.shape[0], -1)\n",
        "\n",
        "        # $\\mu$\n",
        "        mu = self.mu_head(x)\n",
        "        # $\\hat{\\sigma}$\n",
        "        sigma_hat = self.sigma_head(x)\n",
        "        # $\\sigma = \\exp(\\frac{\\hat{\\sigma}}{2})$\n",
        "        sigma = torch.exp(sigma_hat / 2.)\n",
        "\n",
        "        # Sample $z = \\mu + \\sigma \\cdot \\mathcal{N}(0, I)$\n",
        "        z = mu + sigma * torch.normal(mu.new_zeros(mu.shape), mu.new_ones(mu.shape))\n",
        "      \n",
        "        return z, mu, sigma_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CMTHQo3W6tK"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "test_array = torch.rand((2,1 ,48,48))\n",
        "encoder = EncoderRNN(128)\n",
        "encoder(test_array)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlnI2Xkw-5qY"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    ## Decoder module\n",
        "    This consists of a LSTM\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_z: int, dec_hidden_size: int, n_distributions: int):\n",
        "        super().__init__()\n",
        "        # LSTM takes $[(\\Delta x, \\Delta y, p_1, p_2, p_3); z]$ as input\n",
        "        self.lstm = nn.LSTM(d_z + 5, dec_hidden_size)\n",
        "\n",
        "        # Initial state of the LSTM is $[h_0; c_0] = \\tanh(W_{z}z + b_z)$.\n",
        "        # `init_state` is the linear transformation for this\n",
        "        self.init_state = nn.Linear(d_z, 2 * dec_hidden_size)\n",
        "\n",
        "        # This layer produces outputs for each of the `n_distributions`.\n",
        "        # Each distribution needs six parameters\n",
        "        # $(\\hat{\\Pi_i}, \\mu_{x_i}, \\mu_{y_i}, \\hat{\\sigma_{x_i}}, \\hat{\\sigma_{y_i}} \\hat{\\rho_{xy_i}})$\n",
        "        self.mixtures = nn.Linear(dec_hidden_size, 6 * n_distributions)\n",
        "\n",
        "        # This head is for the logits $(\\hat{q_1}, \\hat{q_2}, \\hat{q_3})$\n",
        "        self.q_head = nn.Linear(dec_hidden_size, 3)\n",
        "        # This is to calculate $\\log(q_k)$ where\n",
        "        # $$q_k = \\operatorname{softmax}(\\hat{q})_k = \\frac{\\exp(\\hat{q_k})}{\\sum_{j = 1}^3 \\exp(\\hat{q_j})}$$\n",
        "        self.q_log_softmax = nn.LogSoftmax(-1)\n",
        "\n",
        "        # These parameters are stored for future reference\n",
        "        self.n_distributions = n_distributions\n",
        "        self.dec_hidden_size = dec_hidden_size\n",
        "\n",
        "    def forward(self, x: torch.Tensor, z: torch.Tensor, state: Optional[Tuple[torch.Tensor, torch.Tensor]]):\n",
        "        # The target/expected vectors of strokes\n",
        "        #self.output_x = self.input_data[:, 1:self.hps.max_seq_len + 1, :]  # [N, max_seq_len, 5]\n",
        "        # vectors of strokes to be fed to decoder (same as above, but lagged behind\n",
        "        # one step to include initial dummy value of (0, 0, 1, 0, 0))\n",
        "        #self.input_x = self.input_data[:, :self.hps.max_seq_len, :]  # [N, max_seq_len, 5]\n",
        "\n",
        "        # Calculate the initial state\n",
        "        if state is None:\n",
        "            # $[h_0; c_0] = \\tanh(W_{z}z + b_z)$\n",
        "            h, c = torch.split(torch.tanh(self.init_state(z)), self.dec_hidden_size, 1)\n",
        "            # `h` and `c` have shapes `[batch_size, lstm_size]`. We want to shape them\n",
        "            # to `[1, batch_size, lstm_size]` because that's the shape used in LSTM.\n",
        "            state = (h.unsqueeze(0).contiguous(), c.unsqueeze(0).contiguous())\n",
        "            #state = torch.cat(state, stroke)\n",
        "\n",
        "        # Run the LSTM\n",
        "        outputs, state = self.lstm(x, state)\n",
        "\n",
        "        # Get $\\log(q)$\n",
        "        q_logits = self.q_log_softmax(self.q_head(outputs))\n",
        "\n",
        "        # Get $(\\hat{\\Pi_i}, \\mu_{x,i}, \\mu_{y,i}, \\hat{\\sigma_{x,i}},\n",
        "        # \\hat{\\sigma_{y,i}} \\hat{\\rho_{xy,i}})$.\n",
        "        # `torch.split` splits the output into 6 tensors of size `self.n_distribution`\n",
        "        # across dimension `2`.\n",
        "        pi_logits, mu_x, mu_y, sigma_x, sigma_y, rho_xy = \\\n",
        "            torch.split(self.mixtures(outputs), self.n_distributions, 2)\n",
        "\n",
        "        # Create a bi-variate Gaussian mixture\n",
        "        # $\\Pi$ and \n",
        "        # $\\mathcal{N}(\\mu_{x}, \\mu_{y}, \\sigma_{x}, \\sigma_{y}, \\rho_{xy})$\n",
        "        # where\n",
        "        # $$\\sigma_{x,i} = \\exp(\\hat{\\sigma_{x,i}}), \\sigma_{y,i} = \\exp(\\hat{\\sigma_{y,i}}),\n",
        "        # \\rho_{xy,i} = \\tanh(\\hat{\\rho_{xy,i}})$$\n",
        "        # and\n",
        "        # $$\\Pi_i = \\operatorname{softmax}(\\hat{\\Pi})_i = \\frac{\\exp(\\hat{\\Pi_i})}{\\sum_{j = 1}^3 \\exp(\\hat{\\Pi_j})}$$\n",
        "        #\n",
        "        # $\\Pi$ is the categorical probabilities of choosing the distribution out of the mixture\n",
        "        # $\\mathcal{N}(\\mu_{x}, \\mu_{y}, \\sigma_{x}, \\sigma_{y}, \\rho_{xy})$.\n",
        "        dist = BivariateGaussianMixture(pi_logits, mu_x, mu_y,\n",
        "                                        torch.exp(sigma_x), torch.exp(sigma_y), torch.tanh(rho_xy))\n",
        "\n",
        "        #\n",
        "        return dist, q_logits, state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2gauz9yfMAc"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "batchSize= 3\n",
        "test_array = torch.rand((batchSize,1 ,48,48))\n",
        "encoder = EncoderRNN(128)\n",
        "z, mu, sigma_hat = encoder(test_array)\n",
        "print(z.shape)\n",
        "# Decode the mixture of distributions and $\\hat{q}$\n",
        "strokes_array = torch.rand(96, batchSize, 5)\n",
        "print(strokes_array.shape)\n",
        "# Concatenate $[(\\Delta x, \\Delta y, p_1, p_2, p_3); z]$\n",
        "z_stack = z.unsqueeze(0).expand(strokes_array.shape[0] - 1, -1, -1)\n",
        "print(z_stack.shape)\n",
        "inputs = torch.cat([strokes_array[:-1], z_stack], 2)\n",
        "\n",
        "decoder = DecoderRNN(128, 512, 20)\n",
        "dist, q_logits, _ = decoder(inputs, z, 0, None, None)\n",
        "print(dist)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8NG3ZGw_A5d"
      },
      "outputs": [],
      "source": [
        "class ReconstructionLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    ## Reconstruction Loss\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, mask: torch.Tensor, target: torch.Tensor,\n",
        "                 dist: 'BivariateGaussianMixture', q_logits: torch.Tensor):\n",
        "        # Get $\\Pi$ and $\\mathcal{N}(\\mu_{x}, \\mu_{y}, \\sigma_{x}, \\sigma_{y}, \\rho_{xy})$\n",
        "        pi, mix = dist.get_distribution()\n",
        "        # `target` has shape `[seq_len, batch_size, 5]` where the last dimension is the features\n",
        "        # $(\\Delta x, \\Delta y, p_1, p_2, p_3)$.\n",
        "        # We want to get $\\Delta x, \\Delta$ y and get the probabilities from each of the distributions\n",
        "        # in the mixture $\\mathcal{N}(\\mu_{x}, \\mu_{y}, \\sigma_{x}, \\sigma_{y}, \\rho_{xy})$.\n",
        "        #\n",
        "        # `xy` will have shape `[seq_len, batch_size, n_distributions, 2]`\n",
        "        xy = target[:, :, 0:2].unsqueeze(-2).expand(-1, -1, dist.n_distributions, -1)\n",
        "        # Calculate the probabilities\n",
        "        # $$p(\\Delta x, \\Delta y) =\n",
        "        # \\sum_{j=1}^M \\Pi_j \\mathcal{N} \\big( \\Delta x, \\Delta y \\vert\n",
        "        # \\mu_{x,j}, \\mu_{y,j}, \\sigma_{x,j}, \\sigma_{y,j}, \\rho_{xy,j}\n",
        "        # \\big)$$\n",
        "        probs = torch.sum(pi.probs * torch.exp(mix.log_prob(xy)), 2)\n",
        "\n",
        "        # $$L_s = - \\frac{1}{N_{max}} \\sum_{i=1}^{N_s} \\log \\big (p(\\Delta x, \\Delta y) \\big)$$\n",
        "        # Although `probs` has $N_{max}$ (`longest_seq_len`) elements, the sum is only taken\n",
        "        # upto $N_s$ because the rest is masked out.\n",
        "        #\n",
        "        # It might feel like we should be taking the sum and dividing by $N_s$ and not $N_{max}$,\n",
        "        # but this will give higher weight for individual predictions in shorter sequences.\n",
        "        # We give equal weight to each prediction $p(\\Delta x, \\Delta y)$ when we divide by $N_{max}$\n",
        "        loss_stroke = -torch.mean(mask * torch.log(1e-5 + probs))\n",
        "\n",
        "        # $$L_p = - \\frac{1}{N_{max}} \\sum_{i=1}^{N_{max}} \\sum_{k=1}^{3} p_{k,i} \\log(q_{k,i})$$\n",
        "        loss_pen = -torch.mean(target[:, :, 2:] * q_logits)\n",
        "\n",
        "        # $$L_R = L_s + L_p$$\n",
        "        return loss_stroke + loss_pen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh7206SX_NV7"
      },
      "outputs": [],
      "source": [
        "class Sampler:\n",
        "    \"\"\"\n",
        "    ## Sampler\n",
        "    This samples a sketch from the decoder and plots it\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoder: EncoderCNN, decoder: DecoderRNN):\n",
        "        self.decoder = decoder\n",
        "        self.encoder = encoder\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    def sample(self, data: torch.Tensor, temperature: float, filename: Optional[str] = None):\n",
        "        # $N_{max}$\n",
        "        longest_seq_len = len(data[0])\n",
        "        \n",
        "        # Get $z$ from the encoder\n",
        "        img = torch.tensor(data[2]).unsqueeze(0).unsqueeze(0).float().to(self.device)        \n",
        "        data = data[0]\n",
        "        z, _, _ = self.encoder(img)\n",
        "\n",
        "        # Start-of-sequence stroke is $(0, 0, 1, 0, 0)$\n",
        "        s = data.new_tensor([0, 0, 1, 0, 0]).to(self.device)\n",
        "        seq = [s]\n",
        "        # Initial decoder is `None`.\n",
        "        # The decoder will initialize it to $[h_0; c_0] = \\tanh(W_{z}z + b_z)$\n",
        "        state = None\n",
        "\n",
        "        # We don't need gradients\n",
        "        with torch.no_grad():\n",
        "            # Sample $N_{max}$ strokes\n",
        "            for i in range(longest_seq_len):\n",
        "                # $[(\\Delta x, \\Delta y, p_1, p_2, p_3); z]$ is the input to the decoder\n",
        "                data = torch.cat([s.view(1, 1, -1), z.unsqueeze(0)], 2)\n",
        "                # Get $\\Pi$, $\\mathcal{N}(\\mu_{x}, \\mu_{y}, \\sigma_{x}, \\sigma_{y}, \\rho_{xy})$,\n",
        "                # $q$ and the next state from the decoder\n",
        "                dist, q_logits, state = self.decoder(data, z, state)\n",
        "                # Sample a stroke\n",
        "                s = self._sample_step(dist, q_logits, temperature)\n",
        "                # Add the new stroke to the sequence of strokes\n",
        "                seq.append(s)\n",
        "                # Stop sampling if $p_3 = 1$. This indicates that sketching has stopped\n",
        "                if s[4] == 1:\n",
        "                    break\n",
        "\n",
        "        # Create a PyTorch tensor of the sequence of strokes\n",
        "        seq = torch.stack(seq)\n",
        "\n",
        "        # Plot the sequence of strokes\n",
        "        self.plot(seq, filename)\n",
        "\n",
        "    @staticmethod\n",
        "    def _sample_step(dist: 'BivariateGaussianMixture', q_logits: torch.Tensor, temperature: float):\n",
        "        # Set temperature $\\tau$ for sampling. This is implemented in class `BivariateGaussianMixture`.\n",
        "        dist.set_temperature(temperature)\n",
        "        # Get temperature adjusted $\\Pi$ and $\\mathcal{N}(\\mu_{x}, \\mu_{y}, \\sigma_{x}, \\sigma_{y}, \\rho_{xy})$\n",
        "        pi, mix = dist.get_distribution()\n",
        "        # Sample from $\\Pi$ the index of the distribution to use from the mixture\n",
        "        idx = pi.sample()[0, 0]\n",
        "\n",
        "        # Create categorical distribution $q$ with log-probabilities `q_logits` or $\\hat{q}$\n",
        "        q = torch.distributions.Categorical(logits=q_logits / temperature)\n",
        "        # Sample from $q$\n",
        "        q_idx = q.sample()[0, 0]\n",
        "\n",
        "        # Sample from the normal distributions in the mixture and pick the one indexed by `idx`\n",
        "        xy = mix.sample()[0, 0, idx]\n",
        "\n",
        "        # Create an empty stroke $(\\Delta x, \\Delta y, q_1, q_2, q_3)$\n",
        "        stroke = q_logits.new_zeros(5)\n",
        "        # Set $\\Delta x, \\Delta y$\n",
        "        stroke[:2] = xy\n",
        "        # Set $q_1, q_2, q_3$\n",
        "        stroke[q_idx + 2] = 1\n",
        "        #\n",
        "        return stroke\n",
        "\n",
        "    @staticmethod\n",
        "    def plot(seq: torch.Tensor, filename: Optional[str] = None):\n",
        "        # Take the cumulative sums of $(\\Delta x, \\Delta y)$ to get $(x, y)$\n",
        "        seq[:, 0:2] = torch.cumsum(seq[:, 0:2], dim=0)\n",
        "        # Create a new numpy array of the form $(x, y, q_2)$\n",
        "        seq[:, 2] = seq[:, 3]\n",
        "        seq = seq[:, 0:3].detach().cpu().numpy()\n",
        "\n",
        "        # Split the array at points where $q_2$ is $1$.\n",
        "        # i.e. split the array of strokes at the points where the pen is lifted from the paper.\n",
        "        # This gives a list of sequence of strokes.\n",
        "        strokes = np.split(seq, np.where(seq[:, 2] > 0)[0] + 1)\n",
        "        # Plot each sequence of strokes\n",
        "        for s in strokes:\n",
        "            plt.plot(s[:, 0], -s[:, 1])\n",
        "        # Don't show axes\n",
        "        plt.axis('off')\n",
        "        # Show the plot\n",
        "        if filename:\n",
        "            plt.savefig(filename)\n",
        "        else:\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sZr9sB0_VpL"
      },
      "outputs": [],
      "source": [
        "class Configs():\n",
        "    \"\"\"\n",
        "    ## Configurations\n",
        "    These are default configurations which can later be adjusted by passing a `dict`.\n",
        "    \"\"\"\n",
        "\n",
        "    # Device configurations to pick the device to run the experiment\n",
        "    #device: torch.device = DeviceConfigs()\n",
        "    #\n",
        "    encoder: EncoderCNN\n",
        "    decoder: DecoderRNN\n",
        "    optimizer: optim.Adam\n",
        "    sampler: Sampler\n",
        "\n",
        "    dataset_name: str\n",
        "    train_loader: DataLoader\n",
        "    valid_loader: DataLoader\n",
        "    train_dataset: StrokesDataset\n",
        "    valid_dataset: StrokesDataset\n",
        "\n",
        "    # Encoder and decoder sizes\n",
        "    enc_hidden_size = 256\n",
        "    dec_hidden_size = 512\n",
        "\n",
        "    # Batch size\n",
        "    batch_size = 100\n",
        "\n",
        "    # Number of features in $z$\n",
        "    d_z = 128\n",
        "    # Number of distributions in the mixture, $M$\n",
        "    n_distributions = 20\n",
        "\n",
        "    # Weight of KL divergence loss, $w_{KL}$\n",
        "    #kl_div_loss_weight = 0.5\n",
        "    # Gradient clipping\n",
        "    grad_clip = 1.\n",
        "    # Temperature $\\tau$ for sampling\n",
        "    temperature = 0.4\n",
        "\n",
        "    # Filter out stroke sequences longer than $200$\n",
        "    max_seq_length = 200\n",
        "\n",
        "    epochs = 100\n",
        "\n",
        "    #kl_div_loss = KLDivLoss()\n",
        "    reconstruction_loss = ReconstructionLoss()\n",
        "\n",
        "    def __init__(self, classes: List[str], device_id: int):\n",
        "        self.last_loss = None\n",
        "        self.device = f'cuda:{device_id}' if torch.cuda.is_available() else 'cpu'\n",
        "        # Initialize encoder & decoder\n",
        "        self.encoder = EncoderCNN(self.d_z).to(self.device)\n",
        "        self.decoder = DecoderRNN(self.d_z, self.dec_hidden_size, self.n_distributions).to(self.device)\n",
        "\n",
        "        # Set optimizer. Things like type of optimizer and learning rate are configurable\n",
        "        #optimizer = OptimizerConfigs()\n",
        "        #optimizer.parameters = list(self.encoder.parameters()) + list(self.decoder.parameters())\n",
        "        #self.optimizer = optimizer\n",
        "        self.optimizer = optim.Adam(list(self.encoder.parameters()) + list(self.decoder.parameters()), lr=0.0001)\n",
        "\n",
        "        # Create sampler\n",
        "        self.sampler = Sampler(self.encoder, self.decoder)\n",
        "\n",
        "        # `npz` file path is `data/sketch/[DATASET NAME].npz`\n",
        "        #data_sets = ['cat.npz', 'duck.npz', 'owl.npz', 'giraffe.npz']\n",
        "        data_sets = [f'{c}.npz' for c in classes]\n",
        "        percentage = 0.1\n",
        "        datasets, png_paths, _ = load_dataset('./', data_sets, percentage)\n",
        "        if not os.path.exists(png_paths['test'][-1]): \n",
        "            render_svg2bitmap('./', data_sets, percentage)\n",
        "\n",
        "        # Create training dataset\n",
        "        self.train_dataset = StrokesDataset(datasets['train'], self.max_seq_length, png_paths['train'])\n",
        "        # Create validation dataset\n",
        "        self.valid_dataset = StrokesDataset(datasets['valid'], self.max_seq_length, png_paths['valid'], self.train_dataset.scale)\n",
        "\n",
        "        # Create training data loader\n",
        "        self.train_loader = DataLoader(self.train_dataset, self.batch_size, shuffle=True)\n",
        "        # Create validation data loader\n",
        "        self.valid_loader = DataLoader(self.valid_dataset, self.batch_size)\n",
        "\n",
        "        self.state_modules = []\n",
        "\n",
        "        self.sampling_images_indices = None\n",
        "        self.train_images_indices = None\n",
        "\n",
        "    def save(self, n_images=12):\n",
        "        \n",
        "        # Init at first time\n",
        "        if not self.sampling_images_indices:\n",
        "            self.sampling_images_indices = [np.random.choice(len(self.valid_dataset)) for i in range(n_images)]\n",
        "        if not self.train_images_indices:\n",
        "            self.train_images_indices = [np.random.choice(len(self.train_dataset)) for i in range(n_images)]\n",
        "\n",
        "        dirname = 'checkpoints'\n",
        "        if not os.path.exists(dirname):\n",
        "            os.makedirs(dirname)\n",
        "\n",
        "        now = datetime.now().strftime('%Y-%m-%d_%H:%M:%S')\n",
        "\n",
        "        torch.save({\n",
        "            'encoder': self.encoder.state_dict(),\n",
        "            'decoder': self.decoder.state_dict()\n",
        "        }, os.path.join(dirname, f'model-{now}.dict'))\n",
        "\n",
        "        plt.close()\n",
        "        plt.figure(figsize=(28,20))\n",
        "        plt.tight_layout()\n",
        "\n",
        "        plt.subplot(n_images, 6, 1)\n",
        "        filename = os.path.join(dirname, f'model-{now}-train.png')\n",
        "        for i, index in enumerate(self.sampling_images_indices):\n",
        "            plt.subplot(n_images, 6, i*6+1)\n",
        "            plt.title(f'Train dataset image {index}')\n",
        "            data_ = self.train_dataset[index]\n",
        "            Sampler.plot(data_[0].clone(), filename)\n",
        "            #data_ = data.unsqueeze(1).to(self.device)\n",
        "            for j, temperature in enumerate(np.linspace(0.01, 0.99, 5)):\n",
        "                plt.subplot(n_images, 6, i*6+2+j)\n",
        "                plt.title(f'temperature={temperature}')\n",
        "                self.sampler.sample(data_, temperature, filename)\n",
        "\n",
        "        plt.close()\n",
        "        plt.figure(figsize=(20,18))\n",
        "        plt.tight_layout()\n",
        "\n",
        "        plt.subplot(n_images, 6, 1)\n",
        "        filename = os.path.join(dirname, f'model-{now}-validation.png')\n",
        "        for i, index in enumerate(self.sampling_images_indices):\n",
        "            plt.subplot(n_images, 6, i*6+1)\n",
        "            plt.title(f'Validation dataset image {index}')\n",
        "            data_ = self.valid_dataset[index]\n",
        "            Sampler.plot(data_[0].clone(), filename)\n",
        "            #data_ = data.unsqueeze(1).to(self.device)\n",
        "            for j, temperature in enumerate(np.linspace(0.01, 0.99, 5)):\n",
        "                plt.subplot(n_images, 6, i*6+2+j)\n",
        "                plt.title(f'temperature={temperature}')\n",
        "                self.sampler.sample(data_, temperature, filename)\n",
        "\n",
        "                \n",
        "    def load(self, path):\n",
        "        checkpoint = torch.load(path)\n",
        "        self.encoder.load_state_dict(checkpoint['encoder'])\n",
        "        self.decoder.load_state_dict(checkpoint['decoder'])\n",
        "\n",
        "\n",
        "    def step(self, batch: Any, is_train=True):\n",
        "        self.encoder.train(is_train)\n",
        "        self.decoder.train(is_train)\n",
        "\n",
        "        # Move `data` and `mask` to device and swap the sequence and batch dimensions.\n",
        "        # `data` will have shape `[seq_len, batch_size, 5]` and\n",
        "        # `mask` will have shape `[seq_len, batch_size]`.\n",
        "        data = batch[0].to(self.device).transpose(0, 1)\n",
        "        mask = batch[1].to(self.device).transpose(0, 1)\n",
        "        img = batch[2].to(self.device).view(len(batch[2]), 1, 48,48).float()\n",
        "\n",
        "        z, mu, sigma_hat = self.encoder(img)\n",
        "\n",
        "        # Decode the mixture of distributions and $\\hat{q}$\n",
        "\n",
        "        # Concatenate $[(\\Delta x, \\Delta y, p_1, p_2, p_3); z]$\n",
        "        z_stack = z.unsqueeze(0).expand(data.shape[0] - 1, -1, -1)\n",
        "        inputs = torch.cat([data[:-1], z_stack], 2)\n",
        "        # Get mixture of distributions and $\\hat{q}$\n",
        "        dist, q_logits, _ = self.decoder(inputs, z, None)\n",
        "\n",
        "        # Compute the loss\n",
        "        # $L_{KL}$\n",
        "        #kl_loss = self.kl_div_loss(sigma_hat, mu)\n",
        "        # $L_R$\n",
        "        reconstruction_loss = self.reconstruction_loss(mask, data[1:], dist, q_logits)\n",
        "\n",
        "        # $Loss = L_R + w_{KL} L_{KL}$\n",
        "        loss = reconstruction_loss # + self.kl_div_loss_weight * kl_loss\n",
        "\n",
        "        self.last_loss = loss\n",
        "\n",
        "        # Only if we are in training state\n",
        "        if is_train:\n",
        "\n",
        "            # Set `grad` to zero\n",
        "            self.optimizer.zero_grad()            \n",
        "            # Compute gradients\n",
        "            loss.backward()\n",
        "            #print(loss.item(), end='\\r')\n",
        "            # Clip gradients\n",
        "            nn.utils.clip_grad_norm_(self.encoder.parameters(), self.grad_clip)\n",
        "            nn.utils.clip_grad_norm_(self.decoder.parameters(), self.grad_clip)\n",
        "            # Optimize\n",
        "            self.optimizer.step()\n",
        "        \n",
        "\n",
        "\n",
        "    def sample(self, filename: Optional[str] = None):\n",
        "        # Randomly pick a sample from validation dataset to encoder\n",
        "        data = self.valid_dataset[np.random.choice(len(self.valid_dataset))]\n",
        "        \n",
        "        # Add batch dimension and move it to device\n",
        "        #data = data.unsqueeze(1).to(self.device)\n",
        "        # Sample\n",
        "        self.sampler.sample(data, self.temperature, filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPY1E43sAnhb"
      },
      "outputs": [],
      "source": [
        "#classes = ['cat', 'pig']\n",
        "classes = ['cat']\n",
        "device_id = 0\n",
        "c = Configs(classes, device_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNJILEbgBjiP"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "epochs = 255\n",
        "#c.load('./checkpoints/model-2022-12-08_11:28:47.dict')\n",
        "for i in range(epochs):\n",
        "  for batch in tqdm(c.train_loader):\n",
        "    c.step(batch)\n",
        "  if i % 15 == 0:  \n",
        "    c.save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9g8gchrtEOOx"
      },
      "outputs": [],
      "source": [
        "c.sample()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
